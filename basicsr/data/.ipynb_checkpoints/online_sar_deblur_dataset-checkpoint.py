# # basicsr/data/online_sar_dataset.py
# import sys
# import cv2
# import math
# import numpy as np
# import random
# import os
# import torch
# from torch.utils import data as data
# from basicsr.data.transforms import augment
# sys.path.append(os.path.abspath(os.path.join(__file__, os.path.pardir, os.path.pardir)))
# from basicsr.utils import FileClient, imfrombytes, scandir
# from basicsr.utils.registry import DATASET_REGISTRY
# from typing import Optional, Dict, List, Tuple
# from basicsr.utils import FileClient, imfrombytes, img2tensor, scandir

# # =======================================================================================
# # == åŒºåŸŸä¸€: æ¨¡ç³Šæ ¸ç”Ÿæˆå‡½æ•°åº“ ==
# # == è¯´æ˜: è¿™éƒ¨åˆ†åŒ…å«äº†æ‰€æœ‰æ¨¡ç³Šæ ¸çš„æ•°å­¦å®šä¹‰å’Œéšæœºç”Ÿæˆå‡½æ•°ï¼Œæ˜¯åœ¨çº¿é€€åŒ–çš„åŸºç¡€ã€‚==
# # =======================================================================================
# def bivariate_Gaussian(kernel_size: int, sig_x: float, sig_y: float, theta: float, grid: Optional[np.ndarray] = None, isotropic: bool = True) -> np.ndarray:
#     """ç”Ÿæˆä¸€ä¸ªåŒå˜é‡é«˜æ–¯æ ¸ã€‚"""
#     if grid is None: grid, _, _ = mesh_grid(kernel_size)
#     sigma_matrix = np.array([[sig_x**2, 0], [0, sig_x**2]]) if isotropic else sigma_matrix2(sig_x, sig_y, theta)
#     kernel = pdf2(sigma_matrix, grid)
#     if np.sum(kernel) == 0:
#         kernel = np.zeros((kernel_size, kernel_size)); kernel[kernel_size // 2, kernel_size // 2] = 1.0
#         return kernel
#     return kernel / np.sum(kernel)

# def bivariate_generalized_Gaussian(kernel_size: int, sig_x: float, sig_y: float, theta: float, beta: float, grid: Optional[np.ndarray] = None, isotropic: bool = True) -> np.ndarray:
#     """ç”Ÿæˆä¸€ä¸ªåŒå˜é‡å¹¿ä¹‰é«˜æ–¯æ ¸ã€‚"""
#     if grid is None: grid, _, _ = mesh_grid(kernel_size)
#     sigma_matrix = np.array([[sig_x**2, 0], [0, sig_x**2]]) if isotropic else sigma_matrix2(sig_x, sig_y, theta)
#     try: inverse_sigma = np.linalg.inv(sigma_matrix)
#     except np.linalg.LinAlgError: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
#     exponent_base = np.sum(np.dot(grid, inverse_sigma) * grid, 2)
#     exponent_base[exponent_base < 1e-10] = 1e-10
#     try: powered_term = np.power(exponent_base, beta)
#     except ValueError: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
#     kernel = np.exp(-0.5 * powered_term)
#     if np.sum(kernel) == 0: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
#     return kernel / np.sum(kernel)

# def bivariate_plateau(kernel_size: int, sig_x: float, sig_y: float, theta: float, beta: float, grid: Optional[np.ndarray] = None, isotropic: bool = True) -> np.ndarray:
#     """ç”Ÿæˆä¸€ä¸ªå¹³å°å‹çš„åŒå˜é‡æ ¸ã€‚"""
#     if grid is None: grid, _, _ = mesh_grid(kernel_size)
#     sigma_matrix = np.array([[sig_x**2, 0], [0, sig_x**2]]) if isotropic else sigma_matrix2(sig_x, sig_y, theta)
#     try: inverse_sigma = np.linalg.inv(sigma_matrix)
#     except np.linalg.LinAlgError: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
#     exponent_base = np.sum(np.dot(grid, inverse_sigma) * grid, 2)
#     exponent_base[exponent_base < 1e-10] = 1e-10
#     try: powered_term = np.power(exponent_base, beta)
#     except ValueError: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
#     kernel = np.reciprocal(powered_term + 1)
#     if np.sum(kernel) == 0: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
#     return kernel / np.sum(kernel)

# def sigma_matrix2(sig_x: float, sig_y: float, theta: float) -> np.ndarray:
#     sig_x, sig_y = max(sig_x, 1e-6), max(sig_y, 1e-6)
#     d_matrix = np.array([[sig_x**2, 0], [0, sig_y**2]])
#     u_matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])
#     return np.dot(u_matrix, np.dot(d_matrix, u_matrix.T))

# def mesh_grid(kernel_size: int):
#     ax = np.arange(-kernel_size // 2 + 1., kernel_size // 2 + 1.)
#     xx, yy = np.meshgrid(ax, ax)
#     xy = np.hstack([xx.reshape((-1, 1)), yy.reshape((-1, 1))]).reshape(kernel_size, kernel_size, 2)
#     return xy, xx, yy

# def pdf2(sigma_matrix: np.ndarray, grid: np.ndarray) -> np.ndarray:
#     try: inverse_sigma = np.linalg.inv(sigma_matrix)
#     except np.linalg.LinAlgError: return np.zeros_like(grid[:,:,0])
#     return np.exp(-0.5 * np.sum(np.dot(grid, inverse_sigma) * grid, 2))

# def random_bivariate_Gaussian(kernel_size: int, sigma_x_range: List[float], sigma_y_range: List[float], rotation_range: List[float], isotropic: bool = True) -> np.ndarray:
#     assert kernel_size % 2 == 1
#     sigma_x = np.random.uniform(sigma_x_range[0], sigma_x_range[1])
#     sigma_y, rotation = (sigma_x, 0) if isotropic else (np.random.uniform(sigma_y_range[0], sigma_y_range[1]), np.random.uniform(rotation_range[0], rotation_range[1]))
#     return bivariate_Gaussian(kernel_size, sigma_x, sigma_y, rotation, isotropic=isotropic)

# def random_bivariate_generalized_Gaussian(kernel_size: int, sigma_x_range: List[float], sigma_y_range: List[float], rotation_range: List[float], beta_range: List[float], isotropic: bool = True) -> np.ndarray:
#     assert kernel_size % 2 == 1
#     sigma_x = np.random.uniform(sigma_x_range[0], sigma_x_range[1])
#     sigma_y, rotation = (sigma_x, 0) if isotropic else (np.random.uniform(sigma_y_range[0], sigma_y_range[1]), np.random.uniform(rotation_range[0], rotation_range[1]))
#     beta = np.random.uniform(beta_range[0], beta_range[1])
#     return bivariate_generalized_Gaussian(kernel_size, sigma_x, sigma_y, rotation, beta, isotropic=isotropic)

# def random_bivariate_plateau(kernel_size: int, sigma_x_range: List[float], sigma_y_range: List[float], rotation_range: List[float], beta_range: List[float], isotropic: bool = True) -> np.ndarray:
#     assert kernel_size % 2 == 1
#     sigma_x = np.random.uniform(sigma_x_range[0], sigma_x_range[1])
#     sigma_y, rotation = (sigma_x, 0) if isotropic else (np.random.uniform(sigma_y_range[0], sigma_y_range[1]), np.random.uniform(rotation_range[0], rotation_range[1]))
#     beta = np.random.uniform(beta_range[0], beta_range[1])
#     return bivariate_plateau(kernel_size, sigma_x, sigma_y, rotation, beta, isotropic=isotropic)


# # ============================================================================
# # == åŒºåŸŸäºŒ: æ‰§è¡Œâ€œåœ¨çº¿å•æ¬¡é€€åŒ–â€çš„Datasetç±» (å·²åˆè§„åŒ–) ==
# # ============================================================================
# @DATASET_REGISTRY.register()
# class OnlineSAR_Deblur_Dataset(data.Dataset):
#     """
#     ä¸€ä¸ªæ‰§è¡Œâ€œåœ¨çº¿â€å•æ¬¡é€€åŒ–æ¨¡ç³Šç”Ÿæˆçš„PyTorchæ•°æ®é›†ç±»ï¼Œé€‚é…BasicSRæ¡†æ¶ã€‚
#     ä¿ç•™æ‚¨åŸæœ‰çš„æ¨¡ç³Šæ ¸ç”Ÿæˆé€»è¾‘ï¼Œä»…åšåˆè§„åŒ–è°ƒæ•´ã€‚
#     """

#     def __init__(self, opt):
#         super(OnlineSAR_Deblur_Dataset, self).__init__()
#         self.opt = opt
#         # ä»é…ç½®æ–‡ä»¶(opt)ä¸­è§£æå‚æ•°
#         self.gt_folder = opt['dataroot_gt']
#         self.is_train = 'train' in opt['name']
        
#         # è·å–åœ¨çº¿é€€åŒ–æ‰€éœ€çš„æ¨¡ç³Šæ ¸å‚æ•°
#         self.kernel_options = opt['kernel_options']
#         print(f"[DEBUG] Dataset {opt['name']} ä½¿ç”¨çš„ kernel_list: {self.kernel_options['kernel_list']}")
#         # æ‰«ææ¸…æ™°å›¾åƒæ–‡ä»¶å¤¹ï¼Œè·å–æ‰€æœ‰å›¾åƒçš„è·¯å¾„
#         self.paths = sorted(list(scandir(self.gt_folder, full_path=True)))

#         # æ–­è¨€ï¼šå¿…é¡»æœ‰è·¯å¾„
#         assert self.paths, f'No images found in {self.gt_folder}'

#     def _generate_random_kernel(self):
#         """è¾…åŠ©å‡½æ•°ï¼šæ ¹æ®é…ç½®ç”Ÿæˆä¸€ä¸ªéšæœºæ¨¡ç³Šæ ¸ã€‚"""
#         ko = self.kernel_options
#         kernel_size = random.choice(range(ko['kernel_size_range'][0], ko['kernel_size_range'][1] + 1, 2))
#         kernel_type = np.random.choice(ko['kernel_list'], p=ko['kernel_prob'])
#         isotropic = ko.get('isotropic_options', {}).get(kernel_type, False)
#         try:
#             if 'Gaussian' in kernel_type: 
#                 return random_bivariate_Gaussian(kernel_size, ko['sigma_x_range'], ko['sigma_y_range'], ko['rotation_range'], isotropic=isotropic)
#             elif 'generalized' in kernel_type: 
#                 return random_bivariate_generalized_Gaussian(kernel_size, ko['sigma_x_range'], ko['sigma_y_range'], ko['rotation_range'], ko['betag_range'], isotropic=isotropic)
#             else: 
#                 return random_bivariate_plateau(kernel_size, ko['sigma_x_range'], ko['sigma_y_range'], ko['rotation_range'], ko['betap_range'], isotropic=isotropic)
#         except Exception: 
#             return bivariate_Gaussian(21, 3, 3, 0, isotropic=True)

#     def __getitem__(self, index):
#         """æ ¹æ®ç´¢å¼•è·å–ä¸€ä¸ªæ•°æ®æ ·æœ¬(æ¸…æ™°å›¾, æ¨¡ç³Šå›¾)å¯¹ã€‚"""
#         # 1. åŠ è½½ä¸€å¼ æ¸…æ™°å›¾åƒ (HQ)
#         gt_path = self.paths[index]
#         img_bytes = FileClient().get(gt_path, 'gt')
        
#         # âœ… æ­£ç¡®åŠ è½½å•é€šé“ SAR å›¾åƒ
#         img_gt = imfrombytes(img_bytes, flag='grayscale', float32=True)  # (H, W)

#         # --- æ ¸å¿ƒé€»è¾‘: åœ¨çº¿ç”Ÿæˆæ¨¡ç³Šå›¾åƒ (LQ) ---
#         # 2.1 ç”Ÿæˆä¸€ä¸ªå…¨æ–°çš„éšæœºæ¨¡ç³Šæ ¸
#         kernel = self._generate_random_kernel()
        
#         # 2.2 åº”ç”¨å·ç§¯ç”Ÿæˆæ¨¡ç³Šå›¾åƒ
#         img_lq = cv2.filter2D(img_gt, -1, kernel)  # (H, W)
#         if img_gt.ndim == 2:
#             img_gt = np.expand_dims(img_gt, axis=2) # ä» (H, W) å˜ä¸º (H, W, 1)
#         if img_lq.ndim == 2:
#             img_lq = np.expand_dims(img_lq, axis=2) # ä» (H, W) å˜ä¸º (H, W, 1)
#         # 3. æ•°æ®å¢å¼º (ä½¿ç”¨BasicSRçš„augmentå‡½æ•°)
#         if self.opt.get('use_flip', False) or self.opt.get('use_rot', False):
#             img_gt, img_lq = augment([img_gt, img_lq], self.opt['use_flip'], self.opt['use_rot'])
        
#         # 4. è½¬æ¢ä¸ºTensor (ä½¿ç”¨ img2tensor)
#         img_gt = img2tensor(img_gt, bgr2rgb=False, float32=True)  # (1, H, W)
#         img_lq = img2tensor(img_lq, bgr2rgb=False, float32=True)  # (1, H, W)
        
#         return {
#             'lq': img_lq,
#             'gt': img_gt,
#             'lq_path': gt_path,
#             'gt_path': gt_path
#         }

#     def __len__(self):
#         """è¿”å›æ•°æ®é›†ä¸­æ¸…æ™°å›¾åƒçš„æ€»æ•°ã€‚"""
#         return len(self.paths)

# # ============================================================================
# # == åŒºåŸŸäºŒ: æ‰§è¡Œâ€œåœ¨çº¿å•æ¬¡é€€åŒ–â€çš„Datasetç±» (ä¿®æ”¹åï¼Œæ”¯æŒæµ‹è¯•æ¨¡å¼) ==
# # ============================================================================
# # @DATASET_REGISTRY.register()
# # class OnlineSAR_Deblur_Dataset(data.Dataset):
# #     """
# #     ä¸€ä¸ªæ‰§è¡Œâ€œåœ¨çº¿â€å•æ¬¡é€€åŒ–æ¨¡ç³Šç”Ÿæˆçš„PyTorchæ•°æ®é›†ç±»ï¼Œé€‚é…BasicSRæ¡†æ¶ã€‚
# #     âœ¨ æ–°å¢åŠŸèƒ½ï¼šåœ¨éè®­ç»ƒæ¨¡å¼ä¸‹ï¼Œæ¨¡ç³Šç”Ÿæˆæ˜¯å¯å¤ç°çš„ã€‚
# #     """

# #     def __init__(self, opt):
# #         super(OnlineSAR_Deblur_Dataset, self).__init__()
# #         self.opt = opt
# #         # ä»é…ç½®æ–‡ä»¶(opt)ä¸­è§£æå‚æ•°
# #         self.gt_folder = opt['dataroot_gt']
        
# #         # âœ¨ self.is_train çš„åˆ¤æ–­é€»è¾‘éå¸¸å…³é”®
# #         self.is_train = 'train' in opt['name'].lower()
        
# #         # è·å–åœ¨çº¿é€€åŒ–æ‰€éœ€çš„æ¨¡ç³Šæ ¸å‚æ•°
# #         self.kernel_options = opt['kernel_options']
        
# #         # æ‰«ææ¸…æ™°å›¾åƒæ–‡ä»¶å¤¹ï¼Œè·å–æ‰€æœ‰å›¾åƒçš„è·¯å¾„
# #         self.paths = sorted(list(scandir(self.gt_folder, full_path=True)))

# #         # æ–­è¨€ï¼šå¿…é¡»æœ‰è·¯å¾„
# #         assert self.paths, f'No images found in {self.gt_folder}'
        
# #         # âœ¨ æ·»åŠ ä¸€ä¸ªæ—¥å¿—ï¼Œæ¸…æ™°åœ°å‘ŠçŸ¥å½“å‰æ•°æ®é›†å¤„äºä½•ç§æ¨¡å¼
# #         print(f"Dataset '{self.opt['name']}' initialized in {'TRAIN (Random Blur)' if self.is_train else 'VAL/TEST (Reproducible Blur)'} mode.")
# #         print(f"[INFO] Kernel List for '{self.opt['name']}': {self.kernel_options['kernel_list']} with prob {self.kernel_options['kernel_prob']}")


# #     def _generate_random_kernel(self):
# #         """è¾…åŠ©å‡½æ•°ï¼šæ ¹æ®é…ç½®ç”Ÿæˆä¸€ä¸ªéšæœºæ¨¡ç³Šæ ¸ã€‚"""
# #         ko = self.kernel_options
# #         kernel_size = random.choice(range(ko['kernel_size_range'][0], ko['kernel_size_range'][1] + 1, 2))
# #         kernel_type = np.random.choice(ko['kernel_list'], p=ko['kernel_prob'])
# #         isotropic = ko.get('isotropic_options', {}).get(kernel_type, False)
        
# #         # âœ¨ è¿™é‡Œä»£ç æ²¡å˜ï¼Œä½†æ˜¯è°ƒç”¨å®ƒä¹‹å‰çš„éšæœºç§å­çŠ¶æ€å†³å®šäº†å®ƒçš„è¡Œä¸º
# #         try:
# #             if 'Gaussian' in kernel_type or 'aniso' in kernel_type: # å…¼å®¹'aniso'å‘½å
# #                 return random_bivariate_Gaussian(kernel_size, ko['sigma_x_range'], ko['sigma_y_range'], ko['rotation_range'], isotropic=isotropic)
# #             elif 'generalized' in kernel_type:
# #                 return random_bivariate_generalized_Gaussian(kernel_size, ko['sigma_x_range'], ko['sigma_y_range'], ko['rotation_range'], ko['betag_range'], isotropic=isotropic)
# #             else: # 'plateau'
# #                 # âœ¨ ä¿®å¤äº†ä¸€ä¸ªå°ç¬”è¯¯ï¼ŒåŸä»£ç ä¸­ random_bivariate_plateau è¯¯ç”¨äº† sig_x, sig_y
# #                 sigma_x = np.random.uniform(ko['sigma_x_range'][0], ko['sigma_x_range'][1])
# #                 sigma_y, rotation = (sigma_x, 0) if isotropic else (np.random.uniform(ko['sigma_y_range'][0], ko['sigma_y_range'][1]), np.random.uniform(ko['rotation_range'][0], ko['rotation_range'][1]))
# #                 beta = np.random.uniform(ko['betap_range'][0], ko['betap_range'][1])
# #                 return bivariate_plateau(kernel_size, sigma_x, sigma_y, rotation, beta, isotropic=isotropic)
# #         except Exception as e:
# #             print(f"Kernel generation failed: {e}. Falling back to default Gaussian.")
# #             return bivariate_Gaussian(21, 3, 3, 0, isotropic=True)

# #     def __getitem__(self, index):
# #         """æ ¹æ®ç´¢å¼•è·å–ä¸€ä¸ªæ•°æ®æ ·æœ¬(æ¸…æ™°å›¾, æ¨¡ç³Šå›¾)å¯¹ã€‚"""

# #         # âœ¨âœ¨âœ¨ æ ¸å¿ƒä¿®æ”¹ç‚¹ âœ¨âœ¨âœ¨
# #         # å¦‚æœä¸æ˜¯è®­ç»ƒæ¨¡å¼ï¼ˆå³éªŒè¯æˆ–æµ‹è¯•ï¼‰ï¼Œåˆ™æ ¹æ®å›¾åƒç´¢å¼•è®¾ç½®éšæœºç§å­ã€‚
# #         # è¿™èƒ½ç¡®ä¿å¯¹äºåŒä¸€å¼ å›¾ç‰‡(indexç›¸åŒ)ï¼Œæ¯æ¬¡ç”Ÿæˆçš„"éšæœº"æ¨¡ç³Šæ ¸éƒ½æ˜¯ä¸€æ ·çš„ã€‚
# #         if not self.is_train:
# #             np.random.seed(index)
# #             random.seed(index)

# #         # 1. åŠ è½½ä¸€å¼ æ¸…æ™°å›¾åƒ (HQ)
# #         gt_path = self.paths[index]
# #         img_bytes = FileClient().get(gt_path, 'gt')
        
# #         # âœ… æ­£ç¡®åŠ è½½å•é€šé“ SAR å›¾åƒ
# #         img_gt = imfrombytes(img_bytes, flag='grayscale', float32=True)  # (H, W)

# #         # --- æ ¸å¿ƒé€»è¾‘: åœ¨çº¿ç”Ÿæˆæ¨¡ç³Šå›¾åƒ (LQ) ---
# #         # 2.1 ç”Ÿæˆæ¨¡ç³Šæ ¸ (åœ¨æµ‹è¯•æ¨¡å¼ä¸‹ï¼Œè¿™ä¸€æ­¥æ˜¯å¯å¤ç°çš„)
# #         kernel = self._generate_random_kernel()
        
# #         # 2.2 åº”ç”¨å·ç§¯ç”Ÿæˆæ¨¡ç³Šå›¾åƒ
# #         img_lq = cv2.filter2D(img_gt, -1, kernel)  # (H, W)

# #         # ç¡®ä¿å›¾åƒæ˜¯ 3D çš„ (H, W, C)
# #         if img_gt.ndim == 2:
# #             img_gt = np.expand_dims(img_gt, axis=2) # ä» (H, W) å˜ä¸º (H, W, 1)
# #         if img_lq.ndim == 2:
# #             img_lq = np.expand_dims(img_lq, axis=2) # ä» (H, W) å˜ä¸º (H, W, 1)

# #         # 3. æ•°æ®å¢å¼º (åœ¨æµ‹è¯•æ—¶ï¼Œé…ç½®æ–‡ä»¶ä¸­åº”å…³é—­)
# #         if self.is_train and (self.opt.get('use_flip', False) or self.opt.get('use_rot', False)):
# #             img_gt, img_lq = augment([img_gt, img_lq], self.opt['use_flip'], self.opt['use_rot'])
        
# #         # 4. è½¬æ¢ä¸ºTensor (ä½¿ç”¨ img2tensor)
# #         img_gt = img2tensor(img_gt, bgr2rgb=False, float32=True)  # (1, H, W)
# #         img_lq = img2tensor(img_lq, bgr2rgb=False, float32=True)  # (1, H, W)
        
# #         return {
# #             'lq': img_lq,
# #             'gt': img_gt,
# #             'lq_path': gt_path,
# #             'gt_path': gt_path
# #         }

# #     def __len__(self):
# #         """è¿”å›æ•°æ®é›†ä¸­æ¸…æ™°å›¾åƒçš„æ€»æ•°ã€‚"""
# #         return len(self.paths)

# basicsr/data/online_sar_dataset.py (Diagnostic Version with Detailed Logging)
import sys
import cv2
import math
import numpy as np
import random
import os
import torch
from torch.utils import data as data
from basicsr.data.transforms import augment
sys.path.append(os.path.abspath(os.path.join(__file__, os.path.pardir, os.path.pardir)))
from basicsr.utils import FileClient, imfrombytes, scandir
from basicsr.utils.registry import DATASET_REGISTRY
from typing import Optional, Dict, List, Tuple
from basicsr.utils import FileClient, imfrombytes, img2tensor

# =======================================================================================
# == åŒºåŸŸä¸€: æ¨¡ç³Šæ ¸ç”Ÿæˆå‡½æ•°åº“ (å·²ä¿®æ­£BUG) ==
# =======================================================================================

def bivariate_Gaussian(kernel_size: int, sig_x: float, sig_y: float, theta: float, grid: Optional[np.ndarray] = None, isotropic: bool = True) -> np.ndarray:
    if grid is None: grid, _, _ = mesh_grid(kernel_size)
    sigma_matrix = np.array([[sig_x**2, 0], [0, sig_x**2]]) if isotropic else sigma_matrix2(sig_x, sig_y, theta)
    kernel = pdf2(sigma_matrix, grid)
    if np.sum(kernel) == 0:
        kernel = np.zeros((kernel_size, kernel_size)); kernel[kernel_size // 2, kernel_size // 2] = 1.0
        return kernel
    return kernel / np.sum(kernel)

def bivariate_generalized_Gaussian(kernel_size: int, sig_x: float, sig_y: float, theta: float, beta: float, grid: Optional[np.ndarray] = None, isotropic: bool = True) -> np.ndarray:
    if grid is None: grid, _, _ = mesh_grid(kernel_size)
    sigma_matrix = np.array([[sig_x**2, 0], [0, sig_x**2]]) if isotropic else sigma_matrix2(sig_x, sig_y, theta)
    try: inverse_sigma = np.linalg.inv(sigma_matrix)
    except np.linalg.LinAlgError: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
    exponent_base = np.sum(np.dot(grid, inverse_sigma) * grid, 2)
    exponent_base[exponent_base < 1e-10] = 1e-10
    try: powered_term = np.power(exponent_base, beta)
    except ValueError: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
    kernel = np.exp(-0.5 * powered_term)
    if np.sum(kernel) == 0: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
    return kernel / np.sum(kernel)

def bivariate_plateau(kernel_size: int, sig_x: float, sig_y: float, theta: float, beta: float, grid: Optional[np.ndarray] = None, isotropic: bool = True) -> np.ndarray:
    if grid is None: grid, _, _ = mesh_grid(kernel_size)
    sigma_matrix = np.array([[sig_x**2, 0], [0, sig_x**2]]) if isotropic else sigma_matrix2(sig_x, sig_y, theta)
    try: inverse_sigma = np.linalg.inv(sigma_matrix)
    except np.linalg.LinAlgError: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
    exponent_base = np.sum(np.dot(grid, inverse_sigma) * grid, 2)
    exponent_base[exponent_base < 1e-10] = 1e-10
    try: powered_term = np.power(exponent_base, beta)
    except ValueError: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
    kernel = np.reciprocal(powered_term + 1)
    if np.sum(kernel) == 0: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
    return kernel / np.sum(kernel)

def sigma_matrix2(sig_x: float, sig_y: float, theta: float) -> np.ndarray:
    sig_x, sig_y = max(sig_x, 1e-6), max(sig_y, 1e-6)
    d_matrix = np.array([[sig_x**2, 0], [0, sig_y**2]])
    u_matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])
    return np.dot(u_matrix, np.dot(d_matrix, u_matrix.T))

def mesh_grid(kernel_size: int):
    ax = np.arange(-kernel_size // 2 + 1., kernel_size // 2 + 1.)
    xx, yy = np.meshgrid(ax, ax)
    xy = np.hstack([xx.reshape((-1, 1)), yy.reshape((-1, 1))]).reshape(kernel_size, kernel_size, 2)
    return xy, xx, yy

def pdf2(sigma_matrix: np.ndarray, grid: np.ndarray) -> np.ndarray:
    try: inverse_sigma = np.linalg.inv(sigma_matrix)
    except np.linalg.LinAlgError: return np.zeros_like(grid[:,:,0])
    return np.exp(-0.5 * np.sum(np.dot(grid, inverse_sigma) * grid, 2))

def random_bivariate_Gaussian(kernel_size: int, sigma_x_range: List[float], sigma_y_range: List[float], rotation_range: List[float], isotropic: bool = True) -> np.ndarray:
    assert kernel_size % 2 == 1
    sigma_x = np.random.uniform(sigma_x_range[0], sigma_x_range[1])
    sigma_y, rotation = (sigma_x, 0) if isotropic else (np.random.uniform(sigma_y_range[0], sigma_y_range[1]), np.random.uniform(rotation_range[0], rotation_range[1]))
    return bivariate_Gaussian(kernel_size, sigma_x, sigma_y, rotation, isotropic=isotropic)

def random_bivariate_generalized_Gaussian(kernel_size: int, sigma_x_range: List[float], sigma_y_range: List[float], rotation_range: List[float], beta_range: List[float], isotropic: bool = True) -> np.ndarray:
    assert kernel_size % 2 == 1
    sigma_x = np.random.uniform(sigma_x_range[0], sigma_x_range[1])
    sigma_y, rotation = (sigma_x, 0) if isotropic else (np.random.uniform(sigma_y_range[0], sigma_y_range[1]), np.random.uniform(rotation_range[0], rotation_range[1]))
    beta = np.random.uniform(beta_range[0], beta_range[1])
    return bivariate_generalized_Gaussian(kernel_size, sigma_x, sigma_y, rotation, beta, isotropic=isotropic)

def random_bivariate_plateau(kernel_size: int, sigma_x_range: List[float], sigma_y_range: List[float], rotation_range: List[float], beta_range: List[float], isotropic: bool = True) -> np.ndarray:
    assert kernel_size % 2 == 1
    sigma_x = np.random.uniform(sigma_x_range[0], sigma_x_range[1])
    sigma_y, rotation = (sigma_x, 0) if isotropic else (np.random.uniform(sigma_y_range[0], sigma_y_range[1]), np.random.uniform(rotation_range[0], rotation_range[1]))
    beta = np.random.uniform(beta_range[0], beta_range[1])
    return bivariate_plateau(kernel_size, sigma_x, sigma_y, rotation, beta, isotropic=isotropic)


# ============================================================================
# == åŒºåŸŸäºŒ: æ‰§è¡Œâ€œåœ¨çº¿å•æ¬¡é€€åŒ–â€çš„Datasetç±» (å¢åŠ è¯Šæ–­åŠŸèƒ½) ==
# ============================================================================
@DATASET_REGISTRY.register()
class OnlineSAR_Deblur_Dataset(data.Dataset):
    """
    ä¸€ä¸ªæ‰§è¡Œâ€œåœ¨çº¿â€å•æ¬¡é€€åŒ–æ¨¡ç³Šç”Ÿæˆçš„PyTorchæ•°æ®é›†ç±»ï¼Œé€‚é…BasicSRæ¡†æ¶ã€‚
    âœ¨ è¯Šæ–­ç‰ˆæœ¬ï¼šå¢åŠ äº†è¯¦ç»†çš„æ—¥å¿—æ‰“å°åŠŸèƒ½ï¼Œç”¨äºæ£€æŸ¥å‰10ä¸ªæ ·æœ¬çš„æ•°æ®çŠ¶æ€ã€‚
    """

    def __init__(self, opt):
        super(OnlineSAR_Deblur_Dataset, self).__init__()
        self.opt = opt
        self.gt_folder = opt['dataroot_gt']
        self.is_train = 'train' in opt['name'].lower()
        self.kernel_options = opt['kernel_options']
        self.paths = sorted(list(scandir(self.gt_folder, full_path=True)))
        assert self.paths, f'No images found in {self.gt_folder}'
        
        self.dataset_name = self.opt['name']
        self.dataset_unique_id = abs(hash(self.dataset_name)) % (10**8)

        self.save_lq_folder = opt.get('save_lq_folder', None)
        if self.save_lq_folder:
            os.makedirs(self.save_lq_folder, exist_ok=True)
            print(f"INFO: LQ images from dataset '{self.dataset_name}' will be saved to: {self.save_lq_folder}")

        print(f"Dataset '{self.dataset_name}' initialized in {'TRAIN (Random Blur)' if self.is_train else 'VAL/TEST (Reproducible & Isolated Blur)'} mode.")
        
        # ä½¿æ—¥èªŒæ‰“å°ä»£ç¢¼æ›´å¥å£¯
        kernel_list_info = self.kernel_options.get('kernel_list')
        kernel_prob_info = self.kernel_options.get('kernel_prob')
        if kernel_prob_info:
            print(f"[INFO] Kernel info for '{self.dataset_name}': {kernel_list_info} with prob {kernel_prob_info}")
        else:
            print(f"[INFO] Kernel for '{self.dataset_name}': '{kernel_list_info}'")
        
        # âœ¨ æ–°å¢ï¼šä¸€ä¸ªæ ‡å¿—ï¼Œç”¨äºç¡®ä¿åªåœ¨ç¬¬ä¸€ä¸ªepochæ‰“å°è¯¦ç»†ä¿¡æ¯
        self.debug_printed_indices = set()

    def _generate_random_kernel(self):
        # (æ­¤å‡½æ•°å†…éƒ¨é€»è¾‘æ— éœ€ä¿®æ”¹)
        ko = self.kernel_options
        kernel_size = random.choice(range(ko['kernel_size_range'][0], ko['kernel_size_range'][1] + 1, 2))
        
        if isinstance(ko.get('kernel_list'), str):
            kernel_type = ko['kernel_list']
        else:
            kernel_type = np.random.choice(ko['kernel_list'], p=ko['kernel_prob'])

        isotropic = ko.get('isotropic_options', {}).get(kernel_type, False)
        
        try:
            if 'gaussian' in kernel_type.lower() or 'aniso' in kernel_type.lower():
                return random_bivariate_Gaussian(kernel_size, ko['sigma_x_range'], ko['sigma_y_range'], ko['rotation_range'], isotropic=isotropic)
            elif 'generalized' in kernel_type.lower():
                return random_bivariate_generalized_Gaussian(kernel_size, ko['sigma_x_range'], ko['sigma_y_range'], ko['rotation_range'], ko['betag_range'], isotropic=isotropic)
            else: # 'plateau'
                return random_bivariate_plateau(kernel_size, ko['sigma_x_range'], ko['sigma_y_range'], ko['rotation_range'], ko['betap_range'], isotropic=isotropic)
        except Exception as e:
            # è¿™é‡Œçš„é”™è¯¯å›é€€é€»è¾‘åœ¨æ‚¨çš„ä»£ç ä¸­å¯èƒ½å­˜åœ¨å˜é‡æœªå®šä¹‰çš„bugï¼Œå·²ä¿®æ­£
            print(f"Kernel generation failed: {e}. Falling back to default Gaussian.")
            return bivariate_Gaussian(21, 3, 3, 0, isotropic=True)


    def __getitem__(self, index):
        if not self.is_train:
            seed = index + self.dataset_unique_id
            np.random.seed(seed)
            random.seed(seed)

        gt_path = self.paths[index]
        img_bytes = FileClient().get(gt_path, 'gt')
        img_gt_numpy = imfrombytes(img_bytes, flag='grayscale', float32=True)
        
        kernel = self._generate_random_kernel()
        img_lq_numpy = cv2.filter2D(img_gt_numpy, -1, kernel)

        if self.save_lq_folder:
            basename = os.path.basename(gt_path)
            save_path = os.path.join(self.save_lq_folder, basename)
            img_lq_to_save = np.uint8((img_lq_numpy.clip(0, 1) * 255.).round())
            cv2.imwrite(save_path, img_lq_to_save)
            
        # img_bytes = FileClient().get(img_lq_to_save, 'gt')
        # img_lq1_numpy = imfrombytes(img_bytes, flag='grayscale', float32=True)
        
        img_gt_numpy_expanded = np.expand_dims(img_gt_numpy, axis=2)
        img_lq_numpy_expanded = np.expand_dims(img_lq_numpy, axis=2)

        if self.is_train and (self.opt.get('use_flip', False) or self.opt.get('use_rot', False)):
            # æ³¨æ„ï¼šæ•°æ®å¢å¼ºä½œç”¨åœ¨Numpyæ•°ç»„ä¸Š
            img_gt_numpy_expanded, img_lq_numpy_expanded = augment([img_gt_numpy_expanded, img_lq_numpy_expanded], self.opt['use_flip'], self.opt['use_rot'])
        
        img_gt_tensor = img2tensor(img_gt_numpy_expanded, bgr2rgb=False, float32=True)
        img_lq_tensor = img2tensor(img_lq_numpy_expanded, bgr2rgb=False, float32=True)
        
        # âœ¨âœ¨âœ¨ æ ¸å¿ƒä¿®æ”¹ï¼šå¢åŠ è¯¦ç»†çš„è¯Šæ–­æ‰“å°é€»è¾‘ âœ¨âœ¨âœ¨
        # åªå¯¹å‰10å¼ å›¾ç‰‡æ‰“å°ï¼Œå¹¶ä¸”ç¡®ä¿åœ¨å¤šworkeræ—¶ä¸é‡å¤æ‰“å°
#         if index < 10 and index not in self.debug_printed_indices:
#             self.debug_printed_indices.add(index) # è®°å½•å·²æ‰“å°çš„ç´¢å¼•
            
#             print("\n" + "="*70)
#             print(f"--- ğŸ”¬ æ•°æ®ä½“æ£€æŠ¥å‘Š for index: {index} (Dataset: {self.dataset_name}) ğŸ”¬ ---")
            
#             # --- é˜¶æ®µä¸€ï¼šåœ¨çº¿ç”Ÿæˆçš„ Numpy æ•°ç»„ ---
#             print("\n[é˜¶æ®µ 1] åœ¨çº¿ç”Ÿæˆä¸º Numpy æ•°ç»„å (img_lq_numpy):")
#             print(f"  - æ•°æ®ç±»å‹ (dtype): {img_lq_numpy.dtype}")
#             print(f"  - å½¢çŠ¶ (shape):   {img_lq_numpy.shape}")
#             print(f"  - æœ€å°å€¼ (min):   {np.min(img_lq_numpy):.4f}")
#             print(f"  - æœ€å¤§å€¼ (max):   {np.max(img_lq_numpy):.4f}")
#             print(f"  - å¹³å‡å€¼ (mean): {np.mean(img_lq_numpy):.4f}")

#             # --- é˜¶æ®µäºŒï¼šæœ€ç»ˆè½¬æ¢ä¸º PyTorch Tensor å ---
#             print("\n[é˜¶æ®µ 2] è½¬æ¢ä¸º Tensor å (img_lq_tensor):")
#             print(f"  - æ•°æ®ç±»å‹ (dtype): {img_lq_tensor.dtype}")
#             print(f"  - å½¢çŠ¶ (shape):   {img_lq_tensor.shape}")
#             print(f"  - æœ€å°å€¼ (min):   {img_lq_tensor.min():.4f}")
#             print(f"  - æœ€å¤§å€¼ (max):   {img_lq_tensor.max():.4f}")
#             print(f"  - å¹³å‡å€¼ (mean): {img_lq_tensor.mean():.4f}")
            
#             # --- é˜¶æ®µä¸‰ï¼šæ‰“å° Tensor çš„éƒ¨åˆ†æ•°å€¼å†…å®¹ ---
#             if index == 0:
#                 print("\n[é˜¶æ®µ 3] ç¬¬ä¸€ä¸ªæ ·æœ¬ Tensor å·¦ä¸Šè§’ 5x5 å…·ä½“æ•°å€¼:")
#                 print(img_lq_tensor[0, :5, :5])

#             print("="*70 + "\n")

        return {
            'lq': img_lq_tensor, 
            'gt': img_gt_tensor,
            'lq_path': gt_path, 
            'gt_path': gt_path
        }

    def __len__(self):
        return len(self.paths)

# basicsr/data/online_sar_dataset.py (Final Diagnostic Version)
# import sys
# import cv2
# import math
# import numpy as np
# import random
# import os
# import torch
# from torch.utils import data as data
# from basicsr.data.transforms import augment
# sys.path.append(os.path.abspath(os.path.join(__file__, os.path.pardir, os.path.pardir)))
# from basicsr.utils import FileClient, imfrombytes, scandir
# from basicsr.utils.registry import DATASET_REGISTRY
# from typing import Optional, Dict, List, Tuple
# from basicsr.utils import FileClient, imfrombytes, img2tensor
# from torchvision.utils import save_image

# # =======================================================================================
# # åŒºåŸŸä¸€: æ¨¡ç³Šæ ¸ç”Ÿæˆå‡½æ•°åº“ (åŠŸèƒ½å®Œæ•´ï¼Œæ— éœ€ä¿®æ”¹)
# # =======================================================================================

# def bivariate_Gaussian(kernel_size: int, sig_x: float, sig_y: float, theta: float, grid: Optional[np.ndarray] = None, isotropic: bool = True) -> np.ndarray:
#     if grid is None: grid, _, _ = mesh_grid(kernel_size)
#     sigma_matrix = np.array([[sig_x**2, 0], [0, sig_x**2]]) if isotropic else sigma_matrix2(sig_x, sig_y, theta)
#     kernel = pdf2(sigma_matrix, grid)
#     if np.sum(kernel) == 0:
#         kernel = np.zeros((kernel_size, kernel_size)); kernel[kernel_size // 2, kernel_size // 2] = 1.0
#         return kernel
#     return kernel / np.sum(kernel)

# def bivariate_generalized_Gaussian(kernel_size: int, sig_x: float, sig_y: float, theta: float, beta: float, grid: Optional[np.ndarray] = None, isotropic: bool = True) -> np.ndarray:
#     if grid is None: grid, _, _ = mesh_grid(kernel_size)
#     sigma_matrix = np.array([[sig_x**2, 0], [0, sig_x**2]]) if isotropic else sigma_matrix2(sig_x, sig_y, theta)
#     try: inverse_sigma = np.linalg.inv(sigma_matrix)
#     except np.linalg.LinAlgError: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
#     exponent_base = np.sum(np.dot(grid, inverse_sigma) * grid, 2)
#     exponent_base[exponent_base < 1e-10] = 1e-10
#     try: powered_term = np.power(exponent_base, beta)
#     except ValueError: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
#     kernel = np.exp(-0.5 * powered_term)
#     if np.sum(kernel) == 0: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
#     return kernel / np.sum(kernel)

# def bivariate_plateau(kernel_size: int, sig_x: float, sig_y: float, theta: float, beta: float, grid: Optional[np.ndarray] = None, isotropic: bool = True) -> np.ndarray:
#     if grid is None: grid, _, _ = mesh_grid(kernel_size)
#     sigma_matrix = np.array([[sig_x**2, 0], [0, sig_x**2]]) if isotropic else sigma_matrix2(sig_x, sig_y, theta)
#     try: inverse_sigma = np.linalg.inv(sigma_matrix)
#     except np.linalg.LinAlgError: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
#     exponent_base = np.sum(np.dot(grid, inverse_sigma) * grid, 2)
#     exponent_base[exponent_base < 1e-10] = 1e-10
#     try: powered_term = np.power(exponent_base, beta)
#     except ValueError: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
#     kernel = np.reciprocal(powered_term + 1)
#     if np.sum(kernel) == 0: return bivariate_Gaussian(kernel_size, sig_x, sig_y, theta, grid, isotropic)
#     return kernel / np.sum(kernel)

# def sigma_matrix2(sig_x: float, sig_y: float, theta: float) -> np.ndarray:
#     sig_x, sig_y = max(sig_x, 1e-6), max(sig_y, 1e-6)
#     d_matrix = np.array([[sig_x**2, 0], [0, sig_y**2]])
#     u_matrix = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])
#     return np.dot(u_matrix, np.dot(d_matrix, u_matrix.T))

# def mesh_grid(kernel_size: int):
#     ax = np.arange(-kernel_size // 2 + 1., kernel_size // 2 + 1.)
#     xx, yy = np.meshgrid(ax, ax)
#     xy = np.hstack([xx.reshape((-1, 1)), yy.reshape((-1, 1))]).reshape(kernel_size, kernel_size, 2)
#     return xy, xx, yy

# def pdf2(sigma_matrix: np.ndarray, grid: np.ndarray) -> np.ndarray:
#     try: inverse_sigma = np.linalg.inv(sigma_matrix)
#     except np.linalg.LinAlgError: return np.zeros_like(grid[:,:,0])
#     return np.exp(-0.5 * np.sum(np.dot(grid, inverse_sigma) * grid, 2))

# def random_bivariate_Gaussian(kernel_size: int, sigma_x_range: List[float], sigma_y_range: List[float], rotation_range: List[float], isotropic: bool = True) -> np.ndarray:
#     assert kernel_size % 2 == 1
#     sigma_x = np.random.uniform(sigma_x_range[0], sigma_x_range[1])
#     sigma_y, rotation = (sigma_x, 0) if isotropic else (np.random.uniform(sigma_y_range[0], sigma_y_range[1]), np.random.uniform(rotation_range[0], rotation_range[1]))
#     return bivariate_Gaussian(kernel_size, sigma_x, sigma_y, rotation, isotropic=isotropic)

# def random_bivariate_generalized_Gaussian(kernel_size: int, sigma_x_range: List[float], sigma_y_range: List[float], rotation_range: List[float], beta_range: List[float], isotropic: bool = True) -> np.ndarray:
#     assert kernel_size % 2 == 1
#     sigma_x = np.random.uniform(sigma_x_range[0], sigma_x_range[1])
#     sigma_y, rotation = (sigma_x, 0) if isotropic else (np.random.uniform(sigma_y_range[0], sigma_y_range[1]), np.random.uniform(rotation_range[0], rotation_range[1]))
#     beta = np.random.uniform(beta_range[0], beta_range[1])
#     return bivariate_generalized_Gaussian(kernel_size, sigma_x, sigma_y, rotation, beta, isotropic=isotropic)

# def random_bivariate_plateau(kernel_size: int, sigma_x_range: List[float], sigma_y_range: List[float], rotation_range: List[float], beta_range: List[float], isotropic: bool = True) -> np.ndarray:
#     assert kernel_size % 2 == 1
#     sigma_x = np.random.uniform(sigma_x_range[0], sigma_x_range[1])
#     sigma_y, rotation = (sigma_x, 0) if isotropic else (np.random.uniform(sigma_y_range[0], sigma_y_range[1]), np.random.uniform(rotation_range[0], rotation_range[1]))
#     beta = np.random.uniform(beta_range[0], beta_range[1])
#     return bivariate_plateau(kernel_size, sigma_x, sigma_y, rotation, beta, isotropic=isotropic)

# # ============================================================================
# # == åŒºåŸŸäºŒ: æ‰§è¡Œâ€œåœ¨çº¿å•æ¬¡é€€åŒ–â€çš„Datasetç±» (å¢åŠ å·®å¼‚åˆ†æåŠŸèƒ½) ==
# # ============================================================================
# @DATASET_REGISTRY.register()
# class OnlineSAR_Deblur_Dataset(data.Dataset):
#     """
#     ä¸€ä¸ªæ‰§è¡Œâ€œåœ¨çº¿â€å•æ¬¡é€€åŒ–æ¨¡ç³Šç”Ÿæˆçš„PyTorchæ•°æ®é›†ç±»ï¼Œé€‚é…BasicSRæ¡†æ¶ã€‚
#     âœ¨ è¯Šæ–­ç‰ˆæœ¬ï¼šå¢åŠ äº†â€œä¿å­˜-è¯»å–â€å·®å¼‚åˆ†æåŠŸèƒ½ã€‚
#     """

#     def __init__(self, opt):
#         super(OnlineSAR_Deblur_Dataset, self).__init__()
#         self.opt = opt
#         self.gt_folder = opt['dataroot_gt']
#         self.is_train = 'train' in opt['name'].lower()
#         self.kernel_options = opt['kernel_options']
#         self.paths = sorted(list(scandir(self.gt_folder, full_path=True)))
#         assert self.paths, f'No images found in {self.gt_folder}'
        
#         # âœ¨ æ ¸å¿ƒä¿®æ­£ 1: éµå¾ªæ ‡å‡†å®è·µï¼Œåœ¨ __init__ ä¸­å£°æ˜ self.file_client
#         self.file_client = None
#         # ä» YML ä¸­è¯»å– IO åç«¯é…ç½®
#         self.io_backend_opt = self.opt['io_backend']

#         self.dataset_name = self.opt['name']
#         self.dataset_unique_id = abs(hash(self.dataset_name)) % (10**8)

#         self.save_lq_folder = opt.get('save_lq_folder', None)
#         if self.save_lq_folder:
#             os.makedirs(self.save_lq_folder, exist_ok=True)
#             print(f"INFO: LQ images from dataset '{self.dataset_name}' will be saved to: {self.save_lq_folder}")

#         print(f"Dataset '{self.dataset_name}' initialized in {'TRAIN (Random Blur)' if self.is_train else 'VAL/TEST (Reproducible & Isolated Blur)'} mode.")
        
#         kernel_list_info = self.kernel_options.get('kernel_list')
#         kernel_prob_info = self.kernel_options.get('kernel_prob')
#         if kernel_prob_info:
#             print(f"[INFO] Kernel info for '{self.dataset_name}': {kernel_list_info} with prob {kernel_prob_info}")
#         else:
#             print(f"[INFO] Kernel for '{self.dataset_name}': '{kernel_list_info}'")
        
#         self.debug_printed_indices = set()

#     def _generate_random_kernel(self):
#         ko = self.kernel_options
#         kernel_size = random.choice(range(ko['kernel_size_range'][0], ko['kernel_size_range'][1] + 1, 2))
        
#         if isinstance(ko.get('kernel_list'), str):
#             kernel_type = ko['kernel_list']
#         else:
#             kernel_type = np.random.choice(ko['kernel_list'], p=ko['kernel_prob'])

#         isotropic = ko.get('isotropic_options', {}).get(kernel_type, False)
        
#         try:
#             if 'gaussian' in kernel_type.lower() or 'aniso' in kernel_type.lower():
#                 return random_bivariate_Gaussian(kernel_size, ko['sigma_x_range'], ko['sigma_y_range'], ko['rotation_range'], isotropic=isotropic)
#             elif 'generalized' in kernel_type.lower():
#                 return random_bivariate_generalized_Gaussian(kernel_size, ko['sigma_x_range'], ko['sigma_y_range'], ko['rotation_range'], ko['betag_range'], isotropic=isotropic)
#             else: # 'plateau'
#                 return random_bivariate_plateau(kernel_size, ko['sigma_x_range'], ko['sigma_y_range'], ko['rotation_range'], ko['betap_range'], isotropic=isotropic)
#         except Exception as e:
#             # âœ¨ BUGä¿®å¤: æ‚¨çš„ä»£ç ä¸­ï¼Œè¿™é‡Œçš„ except å—å­˜åœ¨é€»è¾‘é—®é¢˜ï¼Œå·²ä¿®æ­£
#             print(f"Kernel generation failed: {e}. Falling back to default Gaussian.")
#             return bivariate_Gaussian(21, 3, 3, 0, isotropic=True)

#     def __getitem__(self, index):
#         # âœ¨ æ ¸å¿ƒä¿®æ­£ 2: åœ¨ __getitem__ å¼€å¤´ä½¿ç”¨æ ‡å‡†æ–¹å¼å»¶è¿Ÿåˆå§‹åŒ– file_client
#         if self.file_client is None:
#             self.file_client = FileClient(
#                 self.io_backend_opt.pop('type'), **self.io_backend_opt)
                
#         if not self.is_train:
#             seed = index + self.dataset_unique_id
#             np.random.seed(seed)
#             random.seed(seed)

#         gt_path = self.paths[index]
#         # âœ¨ æ ¸å¿ƒä¿®æ­£ 3: ä½¿ç”¨ self.file_client è¯»å–æ•°æ®ï¼Œè€Œä¸æ˜¯åˆ›å»ºä¸´æ—¶å¯¹è±¡
#         img_bytes = self.file_client.get(gt_path, 'gt')
#         img_gt_numpy = imfrombytes(img_bytes, flag='grayscale', float32=True)
        
#         kernel = self._generate_random_kernel()
#         img_lq_numpy = cv2.filter2D(img_gt_numpy, -1, kernel)

#         # âœ¨âœ¨âœ¨ å·®å¼‚åˆ†æä¸æ‰“å°é€»è¾‘ âœ¨âœ¨âœ¨
#         # ä»…åœ¨æµ‹è¯•æ¨¡å¼ã€é…ç½®äº†ä¿å­˜è·¯å¾„ä¸”æ˜¯ç¬¬ä¸€ä¸ªworkerå¤„ç†ç¬¬ä¸€ä¸ªæ ·æœ¬æ—¶æ‰§è¡Œ
#         if not self.is_train and self.save_lq_folder and index == 0 and index not in self.debug_printed_indices:
#             self.debug_printed_indices.add(index)
            
#             print("\n" + "="*70)
#             print(f"--- ğŸ”¬ â€œä¿å­˜-è¯»å–â€å·®å¼‚åˆ†æ for index: {index} (Dataset: {self.dataset_name}) ğŸ”¬ ---")
            
#             basename = os.path.basename(gt_path)
#             save_path = os.path.join(self.save_lq_folder, basename)
#             #img_lq_to_save = np.uint8((img_lq_numpy.clip(0, 1) * 255.).round())
            
#             #cv2.imwrite(save_path, img_lq_to_save)
#             img_gt_tensor = img2tensor(np.expand_dims(img_gt_numpy, axis=2), bgr2rgb=False, float32=True)
#             img_lq_tensor = img2tensor(np.expand_dims(img_lq_numpy, axis=2), bgr2rgb=False, float32=True)
#             save_image(img_lq_tensor,save_path)
#             print(f"\n[æ­¥éª¤ 1] åŸå§‹ float32 æ¨¡ç³Šå›¾å·²ä¿å­˜ä¸º uint8 å›¾åƒè‡³: {save_path}")

#             try:
#                 # ä½¿ç”¨ self.file_client ä»è·¯å¾„è¯»å–ï¼Œç¡®ä¿IOåç«¯ä¸æ­£å¸¸æµç¨‹ä¸€è‡´
#                 img_bytes_reread = self.file_client.get(save_path)
#                 img_lq1_numpy = imfrombytes(img_bytes_reread, flag='grayscale', float32=True)
#                 print(f"[æ­¥éª¤ 2] å·²ä» {save_path} é€šè¿‡ FileClient é‡æ–°è¯»å…¥å›¾åƒã€‚")
#             except Exception as e:
#                 print(f"[æ­¥éª¤ 2] é‡æ–°è¯»å–å›¾åƒæ—¶å‡ºé”™: {e}")
#                 img_lq1_numpy = None

#             print("\n--- åˆ†ææŠ¥å‘Š ---")
            
#             if img_lq1_numpy is None:
#                 print("!! æ— æ³•è¿›è¡Œå·®å¼‚åˆ†æï¼Œå› ä¸ºé‡æ–°è¯»å–å›¾åƒå¤±è´¥ã€‚")
#             elif img_lq_numpy.shape != img_lq1_numpy.shape:
#                 print("!! é”™è¯¯ï¼šåŸå§‹å›¾åƒå’Œè¯»å›çš„å›¾åƒå½¢çŠ¶ä¸åŒ¹é…ï¼")
#             else:
#                 diff_map = np.abs(img_lq_numpy - img_lq1_numpy)
#                 avg_diff = np.mean(diff_map)
#                 max_diff = np.max(diff_map)
#                 non_zero_pixels = np.count_nonzero(diff_map > 1e-6) # å¢åŠ ä¸€ä¸ªå°çš„å®¹å¿åº¦
#                 total_pixels = diff_map.size
                
#                 mse = np.mean((img_lq_numpy - img_lq1_numpy) ** 2)
#                 if mse < 1e-10: # é¿å…é™¤ä»¥é›¶
#                     psnr_val = float('inf')
#                 else:
#                     psnr_val = 20 * math.log10(1.0 / math.sqrt(mse))

#                 print(f"åŸå§‹å†…å­˜ä¸­çš„æ¨¡ç³Šå›¾ (lq) vs é‡æ–°è¯»å…¥çš„æ¨¡ç³Šå›¾ (lq1):")
#                 print(f"  - å¹³å‡ç»å¯¹åƒç´ å·®å¼‚: {avg_diff:.8f}")
#                 print(f"  - æœ€å¤§ç»å¯¹åƒç´ å·®å¼‚: {max_diff:.8f}")
#                 print(f"  - å­˜åœ¨å·®å¼‚çš„åƒç´ æ•°: {non_zero_pixels} / {total_pixels} ({non_zero_pixels/total_pixels:.2%})")
#                 print(f"  - ä¸¤è€…é—´çš„PSNR (é‡åŒ–è¯¯å·®): {psnr_val:.2f} dB")

#             print("="*70 + "\n")

#         # --- åç»­æ­£å¸¸æµç¨‹ ---
#         # img_gt_tensor = img2tensor(np.expand_dims(img_gt_numpy, axis=2), bgr2rgb=False, float32=True)
#         # img_lq_tensor = img2tensor(np.expand_dims(img_lq_numpy, axis=2), bgr2rgb=False, float32=True)
#         # save_image(lq_tensor,save_path)
#         return { 'lq': img_lq_tensor, 'gt': img_gt_tensor, 'lq_path': gt_path, 'gt_path': gt_path }

#     def __len__(self):
#         return len(self.paths)

